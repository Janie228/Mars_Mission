{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import os\n",
    "import pymongo\n",
    "import datetime as dt   \n",
    "import html, csv\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'news', 'url': 'https://mars.nasa.gov/news/'}, {'type': 'space', 'url': 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'}, {'type': 'weather', 'url': 'https://twitter.com/marswxreport?lang=en'}, {'type': 'facts', 'url': 'http://space-facts.com/mars/'}, {'type': 'hemispheres', 'url': 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'}]\n"
     ]
    }
   ],
   "source": [
    "# Store all the required urls into a dictionary list by type\n",
    "url_List = []\n",
    "url_dict = {}\n",
    "url_dict[\"type\"] = \"news\"\n",
    "url_dict[\"url\"] = \"https://mars.nasa.gov/news/\"\n",
    "url_List.append(url_dict)\n",
    "url_dict = {}\n",
    "url_dict[\"type\"] = \"space\"\n",
    "url_dict[\"url\"] = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "url_List.append(url_dict)\n",
    "url_dict = {}\n",
    "url_dict[\"type\"] = \"weather\"\n",
    "url_dict[\"url\"] = \"https://twitter.com/marswxreport?lang=en\"\n",
    "url_List.append(url_dict)\n",
    "url_dict = {}\n",
    "url_dict[\"type\"] = \"facts\"\n",
    "url_dict[\"url\"] = \"http://space-facts.com/mars/\"\n",
    "url_List.append(url_dict)\n",
    "url_dict = {}\n",
    "url_dict[\"type\"] = \"hemispheres\"\n",
    "url_dict[\"url\"] = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "url_List.append(url_dict)\n",
    "\n",
    "print(url_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cerberus Hemisphere Enhanced', 'Schiaparelli Hemisphere Enhanced', 'Syrtis Major Hemisphere Enhanced', 'Valles Marineris Hemisphere Enhanced']\n"
     ]
    }
   ],
   "source": [
    "# Store the hemisphere word links into a list\n",
    "hemisphere_List = [\"Cerberus Hemisphere Enhanced\", \"Schiaparelli Hemisphere Enhanced\", \"Syrtis Major Hemisphere Enhanced\", \"Valles Marineris Hemisphere Enhanced\"]\n",
    "\n",
    "print(hemisphere_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "https://mars.nasa.gov/news/\n",
      "space\n",
      "https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
      "weather\n",
      "https://twitter.com/marswxreport?lang=en\n",
      "facts\n",
      "http://space-facts.com/mars/\n",
      "hemispheres\n",
      "https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n"
     ]
    }
   ],
   "source": [
    "for item in url_List:\n",
    "    print(item[\"type\"])\n",
    "    print(item[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    executable_path = {'executable_path': 'C:/Users/Janie228/SCHOOL/Browser_Drivers/chromedriver'}\n",
    "    return Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "{'newsTitle': 'After a Reset, Curiosity Is Operating Normally', 'newsDesc': 'Curiosity has returned to science operations and is once again exploring the clay unit.', 'img_releaseDate': 'December 9, 2010', 'img_featuredTitle': 'Mars Odyssey All Stars: Bacolor Crater', 'img_featuredUrl': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA13664_hires.jpg'}\n",
      "Was a nice sleep, now let me continue...\n",
      "{'newsTitle': 'After a Reset, Curiosity Is Operating Normally', 'newsDesc': 'Curiosity has returned to science operations and is once again exploring the clay unit.', 'img_releaseDate': 'December 9, 2010', 'img_featuredTitle': 'Mars Odyssey All Stars: Bacolor Crater', 'img_featuredUrl': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA13664_hires.jpg', 'marsFacts': {'Equatorial Diameter:': '6,792 km', 'Polar Diameter:': '6,752 km', 'Mass:': '6.42 x 10^23 kg (10.7% Earth)', 'Moons:': '2 (Phobos & Deimos)', 'Orbit Distance:': '227,943,824 km (1.52 AU)', 'Orbit Period:': '687 days (1.9 years)', 'Surface Temperature:': '-153 to 20 Â°C', 'First Record:': '2nd millennium BC', 'Recorded By:': 'Egyptian astronomers'}, 'marsHemisphere': [{'img_title': 'Cerberus Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'img_title': 'Schiaparelli Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'img_title': 'Syrtis Major Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'img_title': 'Valles Marineris Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "# Initialize mars list to store data to upsert into mongodb\n",
    "marsdict = {}\n",
    "browser = init_browser()\n",
    "\n",
    "# Loop thru the scrape list to scrape each site and parse according to the if criteria\n",
    "for item in url_List:\n",
    "#     print(item[\"type\"])\n",
    "#     print(item[\"url\"])\n",
    "    # If item is one of the three types blow, start off without scraping, else scrape\n",
    "    if (item[\"type\"] == \"hemispheres\") or (item[\"type\"] == \"space\") or (item[\"type\"] == \"facts\"):\n",
    "        # If criteria met, visit site, click to result link, parse, store in dictionary\n",
    "        if (item[\"type\"] == \"hemispheres\"):\n",
    "            sphereList = []\n",
    "\n",
    "            for link in hemisphere_List:\n",
    "                soup = ''\n",
    "                i = 0\n",
    "                sphereDict = {}\n",
    "                sphereDict[\"img_title\"] = link.replace(\" Enhanced\", \"\")\n",
    "                \n",
    "                while (soup == '') and (i < 3):\n",
    "                    try:\n",
    "                        browser.visit(item[\"url\"])\n",
    "                        time.sleep(5)\n",
    "                        browser.click_link_by_partial_text(link)\n",
    "                        time.sleep(5)\n",
    "                        html = browser.html\n",
    "                        soup = bs(html, \"html.parser\")\n",
    "\n",
    "                        sphereDict[\"img_url\"] = (soup.find(\"div\", class_ = \"downloads\")).a[\"href\"]\n",
    "                        sphereList.append(sphereDict)  \n",
    "                    except:\n",
    "                        print(\"Connection refused by the server..\")\n",
    "                        print(\"Let me sleep for 5 seconds\")\n",
    "                        print(\"ZZzzzz...\")\n",
    "                        print(marsdict)\n",
    "                        time.sleep(25)\n",
    "                        print(\"Was a nice sleep, now let me continue...\")\n",
    "                        i = i + 1\n",
    "                        continue\n",
    "            \n",
    "            marsdict[\"marsHemisphere\"] = sphereList\n",
    "                \n",
    "        elif item[\"type\"] == \"facts\":\n",
    "            fact_table = pd.read_html(item[\"url\"])[0]\n",
    "            marsdict[\"marsFacts\"] = dict(zip(fact_table[0] , fact_table[1]))\n",
    "\n",
    "        elif item[\"type\"] == \"space\":\n",
    "            soup = ''\n",
    "            i = 0\n",
    "            \n",
    "            while (soup == '') and (i < 3):\n",
    "                try:\n",
    "                    browser.visit(item[\"url\"])\n",
    "                    time.sleep(1)\n",
    "                    browser.click_link_by_partial_text(\"FULL IMAGE\")\n",
    "                    time.sleep(3)\n",
    "                    browser.click_link_by_partial_text(\"more info\")\n",
    "\n",
    "                    html = browser.html\n",
    "                    soup = bs(html, \"html.parser\")\n",
    "\n",
    "                    marsdict[\"img_releaseDate\"] = (soup.find(\"h2\", class_ = \"category_title\")).span.text.replace(\"|\", \"\").strip()\n",
    "                    marsdict[\"img_featuredTitle\"] = soup.find(\"h1\", class_ = \"article_title\").text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").strip()\n",
    "                    marsdict[\"img_featuredUrl\"] = f\"{'https://www.jpl.nasa.gov'}{(soup.find('figure', class_='lede')).a['href']}\"\n",
    "                except:\n",
    "                    print(\"Connection refused by the server..\")\n",
    "                    print(\"Let me sleep for 5 seconds\")\n",
    "                    print(\"ZZzzzz...\")\n",
    "                    print(marsdict)\n",
    "                    time.sleep(25)\n",
    "                    print(\"Was a nice sleep, now let me continue...\")\n",
    "                    i = i + 1\n",
    "                    continue \n",
    "    \n",
    "    else:\n",
    "        soup = ''\n",
    "        i = 0\n",
    "\n",
    "        while (soup == '') and (i < 3):\n",
    "            try:\n",
    "                # Visit site and scrape html\n",
    "                browser.visit(item[\"url\"])\n",
    "\n",
    "                html = browser.html\n",
    "                soup = bs(html, \"html.parser\")\n",
    "\n",
    "                # If criteria met, parse and store in dictionary\n",
    "                if item[\"type\"] == \"news\":              \n",
    "                    marsdict[\"newsTitle\"] = soup.find(\"div\", class_ = \"content_title\").text.strip()\n",
    "                    marsdict[\"newsDesc\"] = soup.find(\"div\", class_ = \"rollover_description_inner\").text.strip()\n",
    "\n",
    "                elif item[\"type\"] == \"weather\":\n",
    "                    browser.click_link_by_partial_text(\"Home\")\n",
    "                    marsdict[\"marsWeather\"]  = (soup.find(\"p\", class_ = \"TweetTextSize\")).text.split(weather.a.text)[0]\n",
    "            #         marsdict[\"marsWeather\"] = weather\n",
    "            except:\n",
    "                print(\"Connection refused by the server..\")\n",
    "                print(\"Let me sleep for 5 seconds\")\n",
    "                print(\"ZZzzzz...\")\n",
    "                print(marsdict)\n",
    "                time.sleep(25)\n",
    "                print(\"Was a nice sleep, now let me continue...\")\n",
    "                i = i + 1\n",
    "                continue \n",
    "\n",
    "browser.quit()\n",
    "print(marsdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   <table>\n",
    "#     <thead>\n",
    "#       <tr>\n",
    "#         <th>Description</th>\n",
    "#         <th>Value</th>\n",
    "#       </tr>\n",
    "#     </thead>\n",
    "#     <tbody>\n",
    "#           {% for row in mars.mars_dict %}\n",
    "#         <tr>\n",
    "#             <td>{{ row }}</td>\n",
    "#             <td>{{ mars.mars_dict[row] }}</td>\n",
    "#         </tr>\n",
    "#           {% endfor %}\n",
    "\n",
    "#     </tbody>\n",
    "#   </table>\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
